# 第9章: 評価メカニズムの実装

**作成支援**: Manus AI

## 数学的定式化の強化

### 重要度・確信度・整合性の数学的定義

トリプルパースペクティブ型戦略AIレーダーの評価メカニズムは、3つの視点（技術・市場・ビジネス）から得られる情報を定量的に評価し、統合的な判断を支援する数学的フレームワークです。本章では、このメカニズムの核心となる重要度・確信度・整合性の数学的定義と実装技術を詳細に解説します。

#### 重要度（Importance）の数学的定義

重要度 I(p,t) は、視点 p における時点 t での情報の戦略的重要性を表す指標です。

**基本定式化**

```
I(p,t) = Σ(i=1 to n) wi × Si(p,t)
```

ここで：
- p ∈ {Technology, Market, Business}: 評価視点
- t: 評価時点
- wi: 第i要素の重み係数（Σwi = 1）
- Si(p,t): 第i要素のスコア（0 ≤ Si ≤ 100）

**構成要素の詳細定義**

1. **影響範囲スコア S1(p,t)**
   ```
   S1(p,t) = min(100, α × log(1 + R(p,t)/R0))
   ```
   - R(p,t): 影響を受ける対象数（顧客数、市場規模等）
   - R0: 基準値（業界平均等）
   - α: 正規化係数

2. **変化の大きさスコア S2(p,t)**
   ```
   S2(p,t) = min(100, β × |ΔM(p,t)|/σM)
   ```
   - ΔM(p,t): 変化量（成長率変化、技術進歩度等）
   - σM: 変化量の標準偏差
   - β: 正規化係数

3. **戦略的関連性スコア S3(p,t)**
   ```
   S3(p,t) = 100 × Σ(j=1 to k) (Cj × Kj(p,t))
   ```
   - Cj: 第j戦略目標の重要度係数
   - Kj(p,t): 第j戦略目標への影響度（0 ≤ Kj ≤ 1）

4. **時間的緊急性スコア S4(p,t)**
   ```
   S4(p,t) = 100 × exp(-λ × T(p,t))
   ```
   - T(p,t): 対応までの時間的猶予
   - λ: 減衰係数

#### 確信度（Confidence）の数学的定義

確信度 C(p,t) は、視点 p における時点 t での情報の信頼性を表す指標です。

**基本定式化**

```
C(p,t) = Π(i=1 to m) Qi(p,t)^vi
```

ここで：
- Qi(p,t): 第i品質要素のスコア（0 ≤ Qi ≤ 1）
- vi: 第i要素の重み指数（Σvi = 1）

**構成要素の詳細定義**

1. **情報源信頼性 Q1(p,t)**
   ```
   Q1(p,t) = Σ(s=1 to ns) (ws × Rs)
   ```
   - ws: 情報源sの重み
   - Rs: 情報源sの信頼性スコア（0 ≤ Rs ≤ 1）

2. **データ品質 Q2(p,t)**
   ```
   Q2(p,t) = (V(p,t)/V0)^γ × Q(p,t)
   ```
   - V(p,t): データ量
   - V0: 基準データ量
   - Q(p,t): データ品質スコア（0 ≤ Q ≤ 1）
   - γ: データ量の重要度指数

3. **一貫性 Q3(p,t)**
   ```
   Q3(p,t) = 1 - (σ(p,t)/μ(p,t))
   ```
   - σ(p,t): データの標準偏差
   - μ(p,t): データの平均値

4. **検証可能性 Q4(p,t)**
   ```
   Q4(p,t) = Σ(v=1 to nv) (wv × Vv(p,t))
   ```
   - wv: 検証方法vの重み
   - Vv(p,t): 検証方法vによる検証度（0 ≤ Vv ≤ 1）

#### 整合性（Coherence）の数学的定義

整合性 H(t) は、時点 t における3つの視点間の評価結果の一致度を表す指標です。

**基本定式化**

```
H(t) = 1 - (1/3) × Σ(i,j∈{T,M,B}, i≠j) D(i,j,t)
```

ここで：
- D(i,j,t): 視点i,j間の距離関数
- T,M,B: Technology, Market, Business視点

**距離関数の定義**

```
D(i,j,t) = √[(I(i,t) - I(j,t))² + (C(i,t) - C(j,t))²] / √2
```

**詳細整合性評価**

1. **視点間一致度**
   ```
   A(t) = 1 - max(|I(T,t) - I(M,t)|, |I(M,t) - I(B,t)|, |I(B,t) - I(T,t)|)/100
   ```

2. **論理的整合性**
   ```
   L(t) = Σ(r=1 to nr) wr × Lr(t)
   ```
   - Lr(t): 第r論理ルールの満足度
   - wr: 第r論理ルールの重み

3. **時間的整合性**
   ```
   Temp(t) = exp(-|Trend(t) - Trend(t-1)|/σTrend)
   ```
   - Trend(t): 時点tでのトレンド指標
   - σTrend: トレンド変動の標準偏差

### アルゴリズム実装の技術的詳細

#### コンセンサス形成アルゴリズム

**段階的コンセンサス形成**

```python
def consensus_formation(perspectives_data, convergence_threshold=0.01, max_iterations=100):
    """
    段階的コンセンサス形成アルゴリズム
    
    Args:
        perspectives_data: 各視点の評価データ
        convergence_threshold: 収束判定閾値
        max_iterations: 最大反復回数
    
    Returns:
        consensus_result: コンセンサス結果
    """
    
    # 初期化
    weights = initialize_weights(perspectives_data)
    consensus_scores = {}
    iteration = 0
    
    while iteration < max_iterations:
        # 各視点の重み付き評価計算
        weighted_evaluations = calculate_weighted_evaluations(
            perspectives_data, weights
        )
        
        # 整合性評価
        coherence_scores = evaluate_coherence(weighted_evaluations)
        
        # 重み更新（整合性に基づく）
        new_weights = update_weights(weights, coherence_scores)
        
        # 収束判定
        if weight_convergence_check(weights, new_weights, convergence_threshold):
            break
            
        weights = new_weights
        iteration += 1
    
    # 最終コンセンサススコア計算
    consensus_scores = calculate_final_consensus(weighted_evaluations, coherence_scores)
    
    return {
        'consensus_scores': consensus_scores,
        'final_weights': weights,
        'iterations': iteration,
        'coherence': coherence_scores
    }

def calculate_weighted_evaluations(perspectives_data, weights):
    """重み付き評価計算"""
    evaluations = {}
    
    for perspective in ['technology', 'market', 'business']:
        importance = perspectives_data[perspective]['importance']
        confidence = perspectives_data[perspective]['confidence']
        
        # 重み付きスコア計算
        weighted_importance = importance * weights[perspective]['importance']
        weighted_confidence = confidence * weights[perspective]['confidence']
        
        evaluations[perspective] = {
            'importance': weighted_importance,
            'confidence': weighted_confidence,
            'combined': weighted_importance * weighted_confidence
        }
    
    return evaluations

def evaluate_coherence(evaluations):
    """整合性評価"""
    perspectives = list(evaluations.keys())
    coherence_matrix = {}
    
    # 視点間距離計算
    for i in range(len(perspectives)):
        for j in range(i+1, len(perspectives)):
            p1, p2 = perspectives[i], perspectives[j]
            
            # ユークリッド距離計算
            distance = math.sqrt(
                (evaluations[p1]['importance'] - evaluations[p2]['importance'])**2 +
                (evaluations[p1]['confidence'] - evaluations[p2]['confidence'])**2
            )
            
            coherence_matrix[f"{p1}_{p2}"] = 1 - (distance / math.sqrt(2))
    
    # 全体整合性スコア
    overall_coherence = sum(coherence_matrix.values()) / len(coherence_matrix)
    
    return {
        'pairwise': coherence_matrix,
        'overall': overall_coherence
    }

def update_weights(current_weights, coherence_scores):
    """重み更新（整合性フィードバック）"""
    new_weights = {}
    coherence_factor = coherence_scores['overall']
    
    for perspective in current_weights:
        # 整合性に基づく重み調整
        adjustment_factor = 1 + (coherence_factor - 0.5) * 0.1
        
        new_weights[perspective] = {
            'importance': current_weights[perspective]['importance'] * adjustment_factor,
            'confidence': current_weights[perspective]['confidence'] * adjustment_factor
        }
    
    # 正規化
    total_importance_weight = sum(w['importance'] for w in new_weights.values())
    total_confidence_weight = sum(w['confidence'] for w in new_weights.values())
    
    for perspective in new_weights:
        new_weights[perspective]['importance'] /= total_importance_weight
        new_weights[perspective]['confidence'] /= total_confidence_weight
    
    return new_weights
```

#### 動的重み調整メカニズム

**適応的重み学習**

```python
class AdaptiveWeightLearner:
    """適応的重み学習クラス"""
    
    def __init__(self, learning_rate=0.01, momentum=0.9):
        self.learning_rate = learning_rate
        self.momentum = momentum
        self.weight_history = []
        self.performance_history = []
        
    def update_weights(self, current_weights, performance_feedback):
        """
        パフォーマンスフィードバックに基づく重み更新
        
        Args:
            current_weights: 現在の重み
            performance_feedback: パフォーマンス評価結果
        
        Returns:
            updated_weights: 更新された重み
        """
        
        # 勾配計算
        gradients = self.calculate_gradients(performance_feedback)
        
        # モメンタム項計算
        if len(self.weight_history) > 0:
            momentum_term = self.momentum * (
                current_weights - self.weight_history[-1]
            )
        else:
            momentum_term = 0
        
        # 重み更新
        updated_weights = current_weights - (
            self.learning_rate * gradients + momentum_term
        )
        
        # 制約適用（重みの合計=1, 非負制約）
        updated_weights = self.apply_constraints(updated_weights)
        
        # 履歴更新
        self.weight_history.append(current_weights)
        self.performance_history.append(performance_feedback)
        
        return updated_weights
    
    def calculate_gradients(self, performance_feedback):
        """パフォーマンス勾配計算"""
        # 数値微分による勾配近似
        gradients = {}
        epsilon = 1e-6
        
        for perspective in performance_feedback:
            gradient = (
                performance_feedback[perspective]['current'] - 
                performance_feedback[perspective]['previous']
            ) / epsilon
            gradients[perspective] = gradient
        
        return gradients
    
    def apply_constraints(self, weights):
        """重み制約適用"""
        # 非負制約
        for perspective in weights:
            for weight_type in weights[perspective]:
                weights[perspective][weight_type] = max(0, weights[perspective][weight_type])
        
        # 正規化（合計=1制約）
        for weight_type in ['importance', 'confidence']:
            total = sum(weights[p][weight_type] for p in weights)
            if total > 0:
                for perspective in weights:
                    weights[perspective][weight_type] /= total
        
        return weights
```

### 性能最適化手法

#### 計算効率化アルゴリズム

**並列処理による高速化**

```python
import concurrent.futures
import numpy as np
from functools import partial

class OptimizedEvaluationEngine:
    """最適化された評価エンジン"""
    
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.cache = {}
        
    def parallel_perspective_evaluation(self, data_batch):
        """並列視点別評価"""
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # 各視点の評価を並列実行
            futures = {}
            
            for perspective in ['technology', 'market', 'business']:
                future = executor.submit(
                    self.evaluate_single_perspective,
                    perspective,
                    data_batch[perspective]
                )
                futures[perspective] = future
            
            # 結果収集
            results = {}
            for perspective, future in futures.items():
                results[perspective] = future.result()
        
        return results
    
    def evaluate_single_perspective(self, perspective, data):
        """単一視点評価（キャッシュ機能付き）"""
        
        # キャッシュキー生成
        cache_key = self.generate_cache_key(perspective, data)
        
        # キャッシュチェック
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # 評価実行
        importance = self.calculate_importance_vectorized(data['metrics'])
        confidence = self.calculate_confidence_vectorized(data['quality'])
        
        result = {
            'importance': importance,
            'confidence': confidence,
            'timestamp': data['timestamp']
        }
        
        # キャッシュ保存
        self.cache[cache_key] = result
        
        return result
    
    def calculate_importance_vectorized(self, metrics):
        """ベクトル化された重要度計算"""
        
        # NumPyによるベクトル化計算
        metrics_array = np.array([
            metrics['impact_scope'],
            metrics['change_magnitude'],
            metrics['strategic_relevance'],
            metrics['time_urgency']
        ])
        
        weights_array = np.array([0.3, 0.2, 0.3, 0.2])
        
        # 重み付き合計（ベクトル内積）
        weighted_score = np.dot(metrics_array, weights_array)
        
        return float(weighted_score)
    
    def calculate_confidence_vectorized(self, quality_metrics):
        """ベクトル化された確信度計算"""
        
        quality_array = np.array([
            quality_metrics['source_reliability'],
            quality_metrics['data_volume_quality'],
            quality_metrics['consistency'],
            quality_metrics['verifiability']
        ])
        
        weights_array = np.array([0.3, 0.2, 0.2, 0.3])
        
        # 重み付き幾何平均
        weighted_product = np.prod(quality_array ** weights_array)
        
        return float(weighted_product)
    
    def generate_cache_key(self, perspective, data):
        """キャッシュキー生成"""
        import hashlib
        
        # データのハッシュ値を計算
        data_str = str(sorted(data.items()))
        hash_obj = hashlib.md5(data_str.encode())
        
        return f"{perspective}_{hash_obj.hexdigest()}"
```

#### メモリ効率化

**ストリーミング処理による大規模データ対応**

```python
class StreamingEvaluationProcessor:
    """ストリーミング評価プロセッサ"""
    
    def __init__(self, batch_size=1000, memory_limit_mb=512):
        self.batch_size = batch_size
        self.memory_limit_bytes = memory_limit_mb * 1024 * 1024
        self.current_memory_usage = 0
        
    def process_large_dataset(self, data_stream):
        """大規模データセットのストリーミング処理"""
        
        batch_buffer = []
        results = []
        
        for data_point in data_stream:
            batch_buffer.append(data_point)
            
            # バッチサイズまたはメモリ制限チェック
            if (len(batch_buffer) >= self.batch_size or 
                self.estimate_memory_usage(batch_buffer) >= self.memory_limit_bytes):
                
                # バッチ処理実行
                batch_results = self.process_batch(batch_buffer)
                results.extend(batch_results)
                
                # バッファクリア
                batch_buffer.clear()
                
                # ガベージコレクション実行
                import gc
                gc.collect()
        
        # 残りのデータ処理
        if batch_buffer:
            batch_results = self.process_batch(batch_buffer)
            results.extend(batch_results)
        
        return results
    
    def process_batch(self, batch_data):
        """バッチデータ処理"""
        
        # バッチ内での並列処理
        with concurrent.futures.ProcessPoolExecutor() as executor:
            # データを小さなチャンクに分割
            chunk_size = len(batch_data) // self.max_workers
            chunks = [
                batch_data[i:i+chunk_size] 
                for i in range(0, len(batch_data), chunk_size)
            ]
            
            # 各チャンクを並列処理
            futures = [
                executor.submit(self.process_chunk, chunk) 
                for chunk in chunks
            ]
            
            # 結果収集
            results = []
            for future in concurrent.futures.as_completed(futures):
                results.extend(future.result())
        
        return results
    
    def estimate_memory_usage(self, data):
        """メモリ使用量推定"""
        import sys
        
        total_size = 0
        for item in data:
            total_size += sys.getsizeof(item)
        
        return total_size
```

#### リアルタイム処理最適化

**イベント駆動型評価システム**

```python
import asyncio
import aioredis
from datetime import datetime, timedelta

class RealTimeEvaluationSystem:
    """リアルタイム評価システム"""
    
    def __init__(self, redis_url="redis://localhost"):
        self.redis_pool = None
        self.evaluation_queue = asyncio.Queue()
        self.result_cache = {}
        self.cache_ttl = timedelta(minutes=30)
        
    async def initialize(self):
        """システム初期化"""
        self.redis_pool = aioredis.ConnectionPool.from_url(
            "redis://localhost", 
            max_connections=20
        )
        
    async def start_evaluation_worker(self):
        """評価ワーカー開始"""
        
        while True:
            try:
                # キューから評価タスク取得
                task = await asyncio.wait_for(
                    self.evaluation_queue.get(), 
                    timeout=1.0
                )
                
                # 評価実行
                result = await self.execute_evaluation(task)
                
                # 結果をRedisに保存
                await self.save_result_to_redis(task['id'], result)
                
                # キューのタスク完了通知
                self.evaluation_queue.task_done()
                
            except asyncio.TimeoutError:
                # タイムアウト時は継続
                continue
            except Exception as e:
                print(f"評価エラー: {e}")
    
    async def execute_evaluation(self, task):
        """非同期評価実行"""
        
        # キャッシュチェック
        cache_key = f"eval_{task['perspective']}_{task['topic_id']}"
        cached_result = self.result_cache.get(cache_key)
        
        if (cached_result and 
            datetime.now() - cached_result['timestamp'] < self.cache_ttl):
            return cached_result['result']
        
        # 評価実行
        start_time = datetime.now()
        
        # 並列で重要度と確信度を計算
        importance_task = asyncio.create_task(
            self.calculate_importance_async(task['data'])
        )
        confidence_task = asyncio.create_task(
            self.calculate_confidence_async(task['data'])
        )
        
        importance, confidence = await asyncio.gather(
            importance_task, confidence_task
        )
        
        execution_time = datetime.now() - start_time
        
        result = {
            'importance': importance,
            'confidence': confidence,
            'execution_time_ms': execution_time.total_seconds() * 1000,
            'timestamp': datetime.now()
        }
        
        # キャッシュ更新
        self.result_cache[cache_key] = {
            'result': result,
            'timestamp': datetime.now()
        }
        
        return result
    
    async def calculate_importance_async(self, data):
        """非同期重要度計算"""
        
        # CPU集約的な計算を別スレッドで実行
        loop = asyncio.get_event_loop()
        
        return await loop.run_in_executor(
            None, 
            self.calculate_importance_sync, 
            data
        )
    
    async def calculate_confidence_async(self, data):
        """非同期確信度計算"""
        
        loop = asyncio.get_event_loop()
        
        return await loop.run_in_executor(
            None, 
            self.calculate_confidence_sync, 
            data
        )
    
    async def save_result_to_redis(self, task_id, result):
        """結果をRedisに保存"""
        
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        await redis.setex(
            f"evaluation_result:{task_id}",
            3600,  # 1時間のTTL
            json.dumps(result, default=str)
        )
        
        await redis.close()
```

この数学的定式化と最適化されたアルゴリズム実装により、トリプルパースペクティブ型戦略AIレーダーは、大規模なデータを効率的に処理し、リアルタイムでの意思決定支援を実現します。各評価指標の数学的基盤により、客観的で再現可能な評価結果を提供し、継続的な学習と改善を通じて評価精度を向上させることができます。


## 実装技術の詳細化

### エンジニア向け詳細実装技術

#### システムアーキテクチャ設計

**マイクロサービス型評価システム**

トリプルパースペクティブ型戦略AIレーダーの評価メカニズムは、スケーラビリティと保守性を確保するため、マイクロサービスアーキテクチャで実装します。

```python
# services/evaluation_service.py
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, List, Optional
import asyncio
import logging
from datetime import datetime

app = FastAPI(title="Evaluation Service", version="1.0.0")

class EvaluationRequest(BaseModel):
    """評価リクエストモデル"""
    topic_id: str
    perspective: str  # 'technology', 'market', 'business'
    data: Dict
    priority: Optional[int] = 1  # 1(高) - 5(低)
    callback_url: Optional[str] = None

class EvaluationResponse(BaseModel):
    """評価レスポンスモデル"""
    evaluation_id: str
    status: str  # 'pending', 'processing', 'completed', 'failed'
    importance_score: Optional[float] = None
    confidence_score: Optional[float] = None
    processing_time_ms: Optional[float] = None
    created_at: datetime

class EvaluationService:
    """評価サービスクラス"""
    
    def __init__(self):
        self.evaluation_engine = OptimizedEvaluationEngine()
        self.result_store = ResultStore()
        self.notification_service = NotificationService()
        
    async def evaluate_perspective(
        self, 
        request: EvaluationRequest,
        background_tasks: BackgroundTasks
    ) -> EvaluationResponse:
        """視点別評価の実行"""
        
        # 評価ID生成
        evaluation_id = self.generate_evaluation_id(request)
        
        # 初期レスポンス作成
        response = EvaluationResponse(
            evaluation_id=evaluation_id,
            status="pending",
            created_at=datetime.now()
        )
        
        # バックグラウンドで評価実行
        background_tasks.add_task(
            self.process_evaluation,
            evaluation_id,
            request
        )
        
        return response
    
    async def process_evaluation(
        self, 
        evaluation_id: str, 
        request: EvaluationRequest
    ):
        """評価処理の実行"""
        
        try:
            # ステータス更新
            await self.result_store.update_status(evaluation_id, "processing")
            
            start_time = datetime.now()
            
            # 評価実行
            result = await self.evaluation_engine.evaluate(
                request.perspective,
                request.data
            )
            
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # 結果保存
            await self.result_store.save_result(
                evaluation_id,
                result,
                processing_time
            )
            
            # ステータス更新
            await self.result_store.update_status(evaluation_id, "completed")
            
            # コールバック通知
            if request.callback_url:
                await self.notification_service.send_callback(
                    request.callback_url,
                    evaluation_id,
                    result
                )
                
        except Exception as e:
            logging.error(f"評価処理エラー: {e}")
            await self.result_store.update_status(evaluation_id, "failed")
            await self.result_store.save_error(evaluation_id, str(e))

@app.post("/evaluate", response_model=EvaluationResponse)
async def evaluate_endpoint(
    request: EvaluationRequest,
    background_tasks: BackgroundTasks
):
    """評価エンドポイント"""
    service = EvaluationService()
    return await service.evaluate_perspective(request, background_tasks)

@app.get("/evaluate/{evaluation_id}", response_model=EvaluationResponse)
async def get_evaluation_result(evaluation_id: str):
    """評価結果取得エンドポイント"""
    result_store = ResultStore()
    result = await result_store.get_result(evaluation_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="評価結果が見つかりません")
    
    return result
```

**データベース設計とORM実装**

```python
# models/evaluation_models.py
from sqlalchemy import Column, Integer, String, Float, DateTime, JSON, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()

class PerspectiveEvaluation(Base):
    """視点別評価テーブル"""
    __tablename__ = "perspective_evaluations"
    
    id = Column(String(50), primary_key=True)
    topic_id = Column(String(50), nullable=False, index=True)
    perspective = Column(String(20), nullable=False, index=True)
    
    # 評価結果
    importance_score = Column(Float, nullable=False)
    confidence_score = Column(Float, nullable=False)
    overall_score = Column(Float, nullable=False)
    
    # 詳細データ
    importance_components = Column(JSON, nullable=False)
    confidence_components = Column(JSON, nullable=False)
    
    # メタデータ
    processing_time_ms = Column(Float, nullable=False)
    algorithm_version = Column(String(20), nullable=False)
    parameters_hash = Column(String(64), nullable=False)
    
    # タイムスタンプ
    created_at = Column(DateTime, default=datetime.now, nullable=False)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)
    
    # インデックス
    __table_args__ = (
        Index('idx_topic_perspective_date', 'topic_id', 'perspective', 'created_at'),
        Index('idx_overall_score', 'overall_score'),
    )

class CoherenceEvaluation(Base):
    """整合性評価テーブル"""
    __tablename__ = "coherence_evaluations"
    
    id = Column(String(50), primary_key=True)
    topic_id = Column(String(50), nullable=False, index=True)
    
    # 整合性スコア
    overall_coherence = Column(Float, nullable=False)
    pairwise_coherence = Column(JSON, nullable=False)
    
    # 詳細分析
    coherence_components = Column(JSON, nullable=False)
    outlier_perspectives = Column(JSON, nullable=True)
    
    # 関連評価ID
    related_evaluation_ids = Column(JSON, nullable=False)
    
    # タイムスタンプ
    created_at = Column(DateTime, default=datetime.now, nullable=False)

class EvaluationParameters(Base):
    """評価パラメータテーブル"""
    __tablename__ = "evaluation_parameters"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    parameter_set_name = Column(String(100), nullable=False, unique=True)
    perspective = Column(String(20), nullable=False)
    
    # パラメータ
    importance_weights = Column(JSON, nullable=False)
    confidence_weights = Column(JSON, nullable=False)
    thresholds = Column(JSON, nullable=False)
    
    # バージョン管理
    version = Column(String(20), nullable=False)
    is_active = Column(Boolean, default=True, nullable=False)
    
    # タイムスタンプ
    created_at = Column(DateTime, default=datetime.now, nullable=False)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)

# データアクセス層
class EvaluationRepository:
    """評価データリポジトリ"""
    
    def __init__(self, session):
        self.session = session
    
    async def save_perspective_evaluation(self, evaluation_data):
        """視点別評価結果の保存"""
        evaluation = PerspectiveEvaluation(**evaluation_data)
        self.session.add(evaluation)
        await self.session.commit()
        return evaluation.id
    
    async def get_perspective_evaluations(self, topic_id: str, date_from=None, date_to=None):
        """視点別評価結果の取得"""
        query = self.session.query(PerspectiveEvaluation).filter(
            PerspectiveEvaluation.topic_id == topic_id
        )
        
        if date_from:
            query = query.filter(PerspectiveEvaluation.created_at >= date_from)
        if date_to:
            query = query.filter(PerspectiveEvaluation.created_at <= date_to)
        
        return await query.all()
    
    async def get_coherence_trend(self, topic_id: str, days: int = 30):
        """整合性トレンドの取得"""
        from_date = datetime.now() - timedelta(days=days)
        
        query = self.session.query(CoherenceEvaluation).filter(
            CoherenceEvaluation.topic_id == topic_id,
            CoherenceEvaluation.created_at >= from_date
        ).order_by(CoherenceEvaluation.created_at)
        
        return await query.all()
```

#### 高度な評価アルゴリズム実装

**機械学習による評価精度向上**

```python
# ml/evaluation_ml.py
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import joblib
from typing import Dict, List, Tuple

class MLEnhancedEvaluator:
    """機械学習強化評価器"""
    
    def __init__(self):
        self.importance_model = None
        self.confidence_model = None
        self.scaler = StandardScaler()
        self.feature_importance = {}
        
    def train_models(self, training_data: pd.DataFrame):
        """評価モデルの訓練"""
        
        # 特徴量とターゲットの分離
        features = self.extract_features(training_data)
        importance_target = training_data['actual_importance']
        confidence_target = training_data['actual_confidence']
        
        # 特徴量の正規化
        features_scaled = self.scaler.fit_transform(features)
        
        # 重要度予測モデルの訓練
        self.importance_model = self.train_importance_model(
            features_scaled, importance_target
        )
        
        # 確信度予測モデルの訓練
        self.confidence_model = self.train_confidence_model(
            features_scaled, confidence_target
        )
        
        # 特徴量重要度の計算
        self.calculate_feature_importance(features.columns)
        
    def train_importance_model(self, features, target):
        """重要度予測モデルの訓練"""
        
        # ハイパーパラメータ最適化
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        rf = RandomForestRegressor(random_state=42)
        grid_search = GridSearchCV(
            rf, param_grid, cv=5, scoring='neg_mean_squared_error'
        )
        grid_search.fit(features, target)
        
        best_model = grid_search.best_estimator_
        
        # クロスバリデーション評価
        cv_scores = cross_val_score(
            best_model, features, target, cv=5, scoring='r2'
        )
        print(f"重要度モデル R² スコア: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        
        return best_model
    
    def train_confidence_model(self, features, target):
        """確信度予測モデルの訓練"""
        
        # 勾配ブースティングを使用
        param_grid = {
            'n_estimators': [100, 200],
            'learning_rate': [0.05, 0.1, 0.15],
            'max_depth': [3, 5, 7]
        }
        
        gb = GradientBoostingRegressor(random_state=42)
        grid_search = GridSearchCV(
            gb, param_grid, cv=5, scoring='neg_mean_squared_error'
        )
        grid_search.fit(features, target)
        
        best_model = grid_search.best_estimator_
        
        # クロスバリデーション評価
        cv_scores = cross_val_score(
            best_model, features, target, cv=5, scoring='r2'
        )
        print(f"確信度モデル R² スコア: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        
        return best_model
    
    def extract_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """特徴量抽出"""
        
        features = pd.DataFrame()
        
        # 基本統計特徴量
        features['data_volume'] = data['data_volume']
        features['source_count'] = data['source_count']
        features['time_span_days'] = data['time_span_days']
        
        # 変化特徴量
        features['change_magnitude'] = data['change_magnitude']
        features['change_velocity'] = data['change_velocity']
        features['change_acceleration'] = data['change_acceleration']
        
        # 市場特徴量
        features['market_size'] = data['market_size']
        features['market_growth_rate'] = data['market_growth_rate']
        features['competitive_intensity'] = data['competitive_intensity']
        
        # 技術特徴量
        features['technology_maturity'] = data['technology_maturity']
        features['innovation_index'] = data['innovation_index']
        features['adoption_rate'] = data['adoption_rate']
        
        # 相互作用特徴量
        features['market_tech_interaction'] = (
            features['market_growth_rate'] * features['technology_maturity']
        )
        features['size_change_interaction'] = (
            features['market_size'] * features['change_magnitude']
        )
        
        return features
    
    def predict_evaluation(self, input_data: Dict) -> Dict:
        """評価予測の実行"""
        
        # 特徴量変換
        features_df = pd.DataFrame([input_data])
        features = self.extract_features(features_df)
        features_scaled = self.scaler.transform(features)
        
        # 予測実行
        importance_pred = self.importance_model.predict(features_scaled)[0]
        confidence_pred = self.confidence_model.predict(features_scaled)[0]
        
        # 予測信頼区間の計算
        importance_std = self.calculate_prediction_std(
            self.importance_model, features_scaled
        )
        confidence_std = self.calculate_prediction_std(
            self.confidence_model, features_scaled
        )
        
        return {
            'importance': {
                'score': float(importance_pred),
                'confidence_interval': [
                    float(importance_pred - 1.96 * importance_std),
                    float(importance_pred + 1.96 * importance_std)
                ]
            },
            'confidence': {
                'score': float(confidence_pred),
                'confidence_interval': [
                    float(confidence_pred - 1.96 * confidence_std),
                    float(confidence_pred + 1.96 * confidence_std)
                ]
            },
            'feature_contributions': self.get_feature_contributions(features_scaled)
        }
    
    def calculate_prediction_std(self, model, features):
        """予測標準偏差の計算"""
        
        # アンサンブルモデルの個別予測を使用
        if hasattr(model, 'estimators_'):
            predictions = np.array([
                estimator.predict(features)[0] 
                for estimator in model.estimators_
            ])
            return np.std(predictions)
        else:
            # 単一モデルの場合は訓練誤差から推定
            return 0.1  # デフォルト値
    
    def save_models(self, filepath_prefix: str):
        """モデルの保存"""
        joblib.dump(self.importance_model, f"{filepath_prefix}_importance.pkl")
        joblib.dump(self.confidence_model, f"{filepath_prefix}_confidence.pkl")
        joblib.dump(self.scaler, f"{filepath_prefix}_scaler.pkl")
        
    def load_models(self, filepath_prefix: str):
        """モデルの読み込み"""
        self.importance_model = joblib.load(f"{filepath_prefix}_importance.pkl")
        self.confidence_model = joblib.load(f"{filepath_prefix}_confidence.pkl")
        self.scaler = joblib.load(f"{filepath_prefix}_scaler.pkl")
```

### 上級BA向け評価ロジックの理解

#### 評価フレームワークの理論的基盤

**多基準意思決定分析（MCDA）の適用**

```python
# analysis/mcda_framework.py
import numpy as np
from typing import Dict, List, Tuple
import pandas as pd

class MCDAEvaluationFramework:
    """多基準意思決定分析評価フレームワーク"""
    
    def __init__(self):
        self.criteria_weights = {}
        self.evaluation_matrix = None
        self.alternatives = []
        self.criteria = []
        
    def setup_evaluation_criteria(self, criteria_config: Dict):
        """評価基準の設定"""
        
        self.criteria = list(criteria_config.keys())
        self.criteria_weights = {
            criterion: config['weight']
            for criterion, config in criteria_config.items()
        }
        
        # 重みの正規化
        total_weight = sum(self.criteria_weights.values())
        self.criteria_weights = {
            k: v/total_weight for k, v in self.criteria_weights.items()
        }
    
    def add_evaluation_data(self, perspective: str, criteria_scores: Dict):
        """評価データの追加"""
        
        if self.evaluation_matrix is None:
            self.evaluation_matrix = pd.DataFrame()
        
        self.alternatives.append(perspective)
        
        # 評価マトリックスに追加
        for criterion, score in criteria_scores.items():
            self.evaluation_matrix.loc[perspective, criterion] = score
    
    def calculate_topsis_score(self) -> Dict[str, float]:
        """TOPSIS法による総合評価"""
        
        # 正規化評価マトリックス
        normalized_matrix = self.normalize_matrix()
        
        # 重み付き正規化マトリックス
        weighted_matrix = self.apply_weights(normalized_matrix)
        
        # 理想解と負理想解の特定
        ideal_solution = weighted_matrix.max()
        negative_ideal = weighted_matrix.min()
        
        # 各代替案の理想解・負理想解からの距離計算
        distances = {}
        for alternative in self.alternatives:
            d_positive = np.sqrt(
                sum((weighted_matrix.loc[alternative, criterion] - ideal_solution[criterion])**2 
                    for criterion in self.criteria)
            )
            d_negative = np.sqrt(
                sum((weighted_matrix.loc[alternative, criterion] - negative_ideal[criterion])**2 
                    for criterion in self.criteria)
            )
            
            # 相対的近接度の計算
            if d_positive + d_negative > 0:
                closeness = d_negative / (d_positive + d_negative)
            else:
                closeness = 0.5
            
            distances[alternative] = closeness
        
        return distances
    
    def calculate_ahp_score(self, pairwise_comparisons: Dict) -> Dict[str, float]:
        """AHP法による総合評価"""
        
        # ペアワイズ比較マトリックスの構築
        comparison_matrix = self.build_comparison_matrix(pairwise_comparisons)
        
        # 固有ベクトル法による重み計算
        eigenvalues, eigenvectors = np.linalg.eig(comparison_matrix)
        max_eigenvalue_index = np.argmax(eigenvalues.real)
        priority_vector = eigenvectors[:, max_eigenvalue_index].real
        
        # 正規化
        priority_vector = priority_vector / np.sum(priority_vector)
        
        # 整合性比率の計算
        consistency_ratio = self.calculate_consistency_ratio(
            comparison_matrix, eigenvalues[max_eigenvalue_index].real
        )
        
        return {
            'priorities': dict(zip(self.alternatives, priority_vector)),
            'consistency_ratio': consistency_ratio
        }
    
    def sensitivity_analysis(self, weight_variations: Dict) -> Dict:
        """感度分析の実行"""
        
        base_scores = self.calculate_topsis_score()
        sensitivity_results = {'base_scores': base_scores}
        
        for variation_name, weight_changes in weight_variations.items():
            # 重みを一時的に変更
            original_weights = self.criteria_weights.copy()
            
            for criterion, change in weight_changes.items():
                if criterion in self.criteria_weights:
                    self.criteria_weights[criterion] *= (1 + change)
            
            # 重みの再正規化
            total_weight = sum(self.criteria_weights.values())
            self.criteria_weights = {
                k: v/total_weight for k, v in self.criteria_weights.items()
            }
            
            # 変更後のスコア計算
            varied_scores = self.calculate_topsis_score()
            sensitivity_results[variation_name] = varied_scores
            
            # 重みを元に戻す
            self.criteria_weights = original_weights
        
        return sensitivity_results
    
    def generate_evaluation_report(self) -> Dict:
        """評価レポートの生成"""
        
        topsis_scores = self.calculate_topsis_score()
        
        # ランキング
        ranking = sorted(topsis_scores.items(), key=lambda x: x[1], reverse=True)
        
        # 基準別分析
        criteria_analysis = {}
        for criterion in self.criteria:
            scores = self.evaluation_matrix[criterion].to_dict()
            criteria_analysis[criterion] = {
                'scores': scores,
                'best_performer': max(scores, key=scores.get),
                'worst_performer': min(scores, key=scores.get),
                'score_range': max(scores.values()) - min(scores.values())
            }
        
        return {
            'overall_ranking': ranking,
            'topsis_scores': topsis_scores,
            'criteria_analysis': criteria_analysis,
            'criteria_weights': self.criteria_weights,
            'evaluation_matrix': self.evaluation_matrix.to_dict()
        }
```

#### ビジネス価値評価の高度化

**価値創出メカニズムの分析**

```python
# analysis/value_analysis.py
class BusinessValueAnalyzer:
    """ビジネス価値分析器"""
    
    def __init__(self):
        self.value_drivers = {}
        self.impact_models = {}
        
    def define_value_drivers(self, drivers_config: Dict):
        """価値ドライバーの定義"""
        
        self.value_drivers = {
            'revenue_impact': {
                'new_market_opportunities': drivers_config.get('new_markets', 0.3),
                'market_share_expansion': drivers_config.get('market_share', 0.25),
                'premium_pricing': drivers_config.get('premium', 0.2),
                'customer_retention': drivers_config.get('retention', 0.25)
            },
            'cost_impact': {
                'operational_efficiency': drivers_config.get('efficiency', 0.4),
                'automation_benefits': drivers_config.get('automation', 0.3),
                'risk_reduction': drivers_config.get('risk_reduction', 0.3)
            },
            'strategic_impact': {
                'competitive_advantage': drivers_config.get('competitive', 0.4),
                'innovation_capability': drivers_config.get('innovation', 0.3),
                'organizational_learning': drivers_config.get('learning', 0.3)
            }
        }
    
    def calculate_business_impact(self, evaluation_data: Dict) -> Dict:
        """ビジネスインパクトの計算"""
        
        impact_results = {}
        
        # 収益インパクト
        revenue_impact = self.calculate_revenue_impact(evaluation_data)
        
        # コストインパクト
        cost_impact = self.calculate_cost_impact(evaluation_data)
        
        # 戦略的インパクト
        strategic_impact = self.calculate_strategic_impact(evaluation_data)
        
        # 総合インパクト
        total_impact = {
            'revenue_impact': revenue_impact,
            'cost_impact': cost_impact,
            'strategic_impact': strategic_impact,
            'net_impact': revenue_impact['total'] + cost_impact['total'] + strategic_impact['total']
        }
        
        return total_impact
    
    def calculate_revenue_impact(self, data: Dict) -> Dict:
        """収益インパクトの計算"""
        
        base_revenue = data.get('base_revenue', 0)
        market_data = data.get('market_data', {})
        
        impacts = {}
        
        # 新市場機会
        new_market_potential = market_data.get('new_market_size', 0)
        market_penetration_rate = data.get('penetration_rate', 0.05)
        impacts['new_markets'] = new_market_potential * market_penetration_rate
        
        # 市場シェア拡大
        current_share = market_data.get('current_share', 0)
        share_increase = data.get('share_increase_potential', 0)
        market_size = market_data.get('total_market_size', 0)
        impacts['share_expansion'] = market_size * share_increase
        
        # プレミアム価格
        premium_rate = data.get('premium_pricing_potential', 0)
        affected_revenue = base_revenue * data.get('premium_applicable_ratio', 0.3)
        impacts['premium_pricing'] = affected_revenue * premium_rate
        
        # 顧客維持
        churn_reduction = data.get('churn_reduction_rate', 0)
        customer_lifetime_value = data.get('customer_ltv', 0)
        customer_base = data.get('customer_count', 0)
        impacts['retention'] = customer_base * churn_reduction * customer_lifetime_value
        
        # 重み付き合計
        total_revenue_impact = sum(
            impacts[driver] * weight
            for driver, weight in self.value_drivers['revenue_impact'].items()
            if driver.replace('_', '') in [k.replace('_', '') for k in impacts.keys()]
        )
        
        return {
            'components': impacts,
            'total': total_revenue_impact,
            'percentage_of_base': total_revenue_impact / base_revenue if base_revenue > 0 else 0
        }
    
    def perform_scenario_analysis(self, base_data: Dict, scenarios: Dict) -> Dict:
        """シナリオ分析の実行"""
        
        scenario_results = {}
        
        # ベースケース
        base_impact = self.calculate_business_impact(base_data)
        scenario_results['base_case'] = base_impact
        
        # 各シナリオの分析
        for scenario_name, scenario_data in scenarios.items():
            # ベースデータにシナリオデータをマージ
            combined_data = {**base_data, **scenario_data}
            scenario_impact = self.calculate_business_impact(combined_data)
            scenario_results[scenario_name] = scenario_impact
        
        # シナリオ比較
        comparison = self.compare_scenarios(scenario_results)
        
        return {
            'scenario_results': scenario_results,
            'comparison': comparison,
            'recommendations': self.generate_scenario_recommendations(comparison)
        }
    
    def calculate_roi_metrics(self, impact_data: Dict, investment_data: Dict) -> Dict:
        """ROI指標の計算"""
        
        total_benefits = impact_data['net_impact']
        total_investment = investment_data.get('total_investment', 0)
        investment_period = investment_data.get('period_years', 3)
        discount_rate = investment_data.get('discount_rate', 0.1)
        
        # 年次キャッシュフロー
        annual_benefits = total_benefits / investment_period
        annual_costs = total_investment / investment_period
        
        # NPV計算
        npv = self.calculate_npv(annual_benefits, annual_costs, discount_rate, investment_period)
        
        # IRR計算（簡易版）
        irr = self.calculate_irr_approximation(annual_benefits, total_investment, investment_period)
        
        # 回収期間
        payback_period = total_investment / annual_benefits if annual_benefits > 0 else float('inf')
        
        return {
            'roi_percentage': (total_benefits / total_investment - 1) * 100 if total_investment > 0 else 0,
            'npv': npv,
            'irr_percentage': irr * 100,
            'payback_period_years': payback_period,
            'benefit_cost_ratio': total_benefits / total_investment if total_investment > 0 else 0
        }
```

### テスト・検証手法

#### 単体テスト・統合テストの実装

```python
# tests/test_evaluation_engine.py
import pytest
import numpy as np
from unittest.mock import Mock, patch
from evaluation_engine import OptimizedEvaluationEngine, MCDAEvaluationFramework

class TestEvaluationEngine:
    """評価エンジンのテストクラス"""
    
    @pytest.fixture
    def evaluation_engine(self):
        """評価エンジンのフィクスチャ"""
        return OptimizedEvaluationEngine()
    
    @pytest.fixture
    def sample_data(self):
        """サンプルデータのフィクスチャ"""
        return {
            'technology': {
                'metrics': {
                    'impact_scope': 75,
                    'change_magnitude': 60,
                    'strategic_relevance': 80,
                    'time_urgency': 50
                },
                'quality': {
                    'source_reliability': 0.85,
                    'data_volume_quality': 0.70,
                    'consistency': 0.75,
                    'verifiability': 0.90
                }
            }
        }
    
    def test_importance_calculation(self, evaluation_engine, sample_data):
        """重要度計算のテスト"""
        
        result = evaluation_engine.calculate_importance_vectorized(
            sample_data['technology']['metrics']
        )
        
        # 期待値の計算
        expected = (75 * 0.3) + (60 * 0.2) + (80 * 0.3) + (50 * 0.2)
        
        assert abs(result - expected) < 0.01
        assert 0 <= result <= 100
    
    def test_confidence_calculation(self, evaluation_engine, sample_data):
        """確信度計算のテスト"""
        
        result = evaluation_engine.calculate_confidence_vectorized(
            sample_data['technology']['quality']
        )
        
        # 幾何平均の期待値
        quality_array = np.array([0.85, 0.70, 0.75, 0.90])
        weights_array = np.array([0.3, 0.2, 0.2, 0.3])
        expected = np.prod(quality_array ** weights_array)
        
        assert abs(result - expected) < 0.01
        assert 0 <= result <= 1
    
    def test_parallel_evaluation(self, evaluation_engine, sample_data):
        """並列評価のテスト"""
        
        # 複数視点のデータを準備
        multi_perspective_data = {
            'technology': sample_data['technology'],
            'market': sample_data['technology'],  # 簡略化のため同じデータを使用
            'business': sample_data['technology']
        }
        
        result = evaluation_engine.parallel_perspective_evaluation(multi_perspective_data)
        
        assert len(result) == 3
        assert all(perspective in result for perspective in ['technology', 'market', 'business'])
        assert all('importance' in result[p] and 'confidence' in result[p] for p in result)
    
    @patch('evaluation_engine.time.time')
    def test_performance_benchmark(self, mock_time, evaluation_engine, sample_data):
        """性能ベンチマークテスト"""
        
        # 実行時間の測定をモック
        mock_time.side_effect = [0, 0.1]  # 100ms の実行時間をシミュレート
        
        result = evaluation_engine.evaluate_single_perspective(
            'technology', sample_data['technology']
        )
        
        # 性能要件の確認（100ms以内）
        execution_time = mock_time.call_count
        assert execution_time <= 2  # start と end の2回の呼び出し
    
    def test_edge_cases(self, evaluation_engine):
        """エッジケースのテスト"""
        
        # 空のデータ
        with pytest.raises(ValueError):
            evaluation_engine.calculate_importance_vectorized({})
        
        # 不正な値
        invalid_data = {
            'impact_scope': -10,  # 負の値
            'change_magnitude': 150,  # 範囲外
            'strategic_relevance': 'invalid',  # 文字列
            'time_urgency': None  # None値
        }
        
        with pytest.raises((ValueError, TypeError)):
            evaluation_engine.calculate_importance_vectorized(invalid_data)

class TestMCDAFramework:
    """MCDA フレームワークのテストクラス"""
    
    @pytest.fixture
    def mcda_framework(self):
        """MCDA フレームワークのフィクスチャ"""
        framework = MCDAEvaluationFramework()
        
        # 評価基準の設定
        criteria_config = {
            'importance': {'weight': 0.4},
            'confidence': {'weight': 0.3},
            'coherence': {'weight': 0.3}
        }
        framework.setup_evaluation_criteria(criteria_config)
        
        return framework
    
    def test_topsis_calculation(self, mcda_framework):
        """TOPSIS 計算のテスト"""
        
        # テストデータの追加
        mcda_framework.add_evaluation_data('technology', {
            'importance': 80, 'confidence': 75, 'coherence': 85
        })
        mcda_framework.add_evaluation_data('market', {
            'importance': 70, 'confidence': 85, 'coherence': 80
        })
        mcda_framework.add_evaluation_data('business', {
            'importance': 90, 'confidence': 70, 'coherence': 75
        })
        
        scores = mcda_framework.calculate_topsis_score()
        
        assert len(scores) == 3
        assert all(0 <= score <= 1 for score in scores.values())
        assert sum(scores.values()) > 0  # 少なくとも一つは正の値
    
    def test_sensitivity_analysis(self, mcda_framework):
        """感度分析のテスト"""
        
        # データ追加
        mcda_framework.add_evaluation_data('technology', {
            'importance': 80, 'confidence': 75, 'coherence': 85
        })
        mcda_framework.add_evaluation_data('market', {
            'importance': 70, 'confidence': 85, 'coherence': 80
        })
        
        # 重み変更シナリオ
        weight_variations = {
            'importance_increase': {'importance': 0.2},  # 20%増加
            'confidence_decrease': {'confidence': -0.1}  # 10%減少
        }
        
        results = mcda_framework.sensitivity_analysis(weight_variations)
        
        assert 'base_scores' in results
        assert 'importance_increase' in results
        assert 'confidence_decrease' in results

# 統合テスト
class TestIntegrationEvaluation:
    """統合評価のテストクラス"""
    
    @pytest.mark.integration
    def test_end_to_end_evaluation(self):
        """エンドツーエンド評価テスト"""
        
        # 実際のAPIエンドポイントを使用した統合テスト
        import requests
        
        test_data = {
            'topic_id': 'test_topic_001',
            'perspective': 'technology',
            'data': {
                'metrics': {
                    'impact_scope': 75,
                    'change_magnitude': 60,
                    'strategic_relevance': 80,
                    'time_urgency': 50
                },
                'quality': {
                    'source_reliability': 0.85,
                    'data_volume_quality': 0.70,
                    'consistency': 0.75,
                    'verifiability': 0.90
                }
            }
        }
        
        # 評価リクエスト送信
        response = requests.post(
            'http://localhost:8000/evaluate',
            json=test_data
        )
        
        assert response.status_code == 202
        
        evaluation_id = response.json()['evaluation_id']
        
        # 結果取得（ポーリング）
        import time
        for _ in range(10):  # 最大10秒待機
            result_response = requests.get(
                f'http://localhost:8000/evaluate/{evaluation_id}'
            )
            
            if result_response.json()['status'] == 'completed':
                break
            
            time.sleep(1)
        
        assert result_response.status_code == 200
        result = result_response.json()
        assert result['status'] == 'completed'
        assert 'importance_score' in result
        assert 'confidence_score' in result

# パフォーマンステスト
class TestPerformance:
    """パフォーマンステストクラス"""
    
    @pytest.mark.performance
    def test_large_batch_processing(self):
        """大量バッチ処理のテスト"""
        
        from evaluation_engine import StreamingEvaluationProcessor
        
        processor = StreamingEvaluationProcessor(batch_size=100)
        
        # 大量のテストデータ生成
        def generate_test_data(count):
            for i in range(count):
                yield {
                    'id': f'test_{i}',
                    'metrics': {
                        'impact_scope': np.random.randint(0, 100),
                        'change_magnitude': np.random.randint(0, 100),
                        'strategic_relevance': np.random.randint(0, 100),
                        'time_urgency': np.random.randint(0, 100)
                    }
                }
        
        start_time = time.time()
        results = processor.process_large_dataset(generate_test_data(10000))
        end_time = time.time()
        
        processing_time = end_time - start_time
        throughput = len(results) / processing_time
        
        # 性能要件：1秒あたり1000件以上の処理
        assert throughput >= 1000
        assert len(results) == 10000

if __name__ == '__main__':
    pytest.main(['-v', '--tb=short'])
```

この実装技術の詳細化により、エンジニアは具体的な開発指針を、上級BAは評価ロジックの理論的基盤を、そして品質保証チームは包括的なテスト戦略を得ることができます。これらの技術要素が統合されることで、トリプルパースペクティブ型戦略AIレーダーの評価メカニズムは、高い精度と信頼性を持つ実用的なシステムとして実現されます。

